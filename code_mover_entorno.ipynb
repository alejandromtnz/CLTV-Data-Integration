{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyodbc in c:\\users\\aleja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba: consulta SQL en la misma query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_19108\\2914783269.py:59: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(SQL_QUERY, conn_azure)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando a Azure SQL...\n",
      "Ejecutando consulta en Azure SQL...\n",
      "   - Datos extra√≠dos: 44053 filas\n",
      "Conectando a SQL Server Local...\n",
      "   - Tabla eliminada si exist√≠a.\n",
      "   - Tabla FACT_SALES creada correctamente en SQL Server Local.\n",
      "   - 44053 filas insertadas en FACT_SALES.\n"
     ]
    }
   ],
   "source": [
    "# import pyodbc\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    " \n",
    "# # Configuraci√≥n de logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# # Conexi√≥n a **Azure SQL**\n",
    "# AZURE_SERVER = 'uaxmathfis.database.windows.net'\n",
    "# AZURE_DATABASE = 'usecases'\n",
    "# AZURE_DRIVER = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "# azure_conn_str = f\"DRIVER={AZURE_DRIVER};SERVER={AZURE_SERVER};DATABASE={AZURE_DATABASE};Authentication=ActiveDirectoryInteractive\"\n",
    "\n",
    "# # Conexi√≥n a **SQL Server LOCAL**\n",
    "# LOCAL_SERVER = 'localhost'\n",
    "# LOCAL_DATABASE = 'master'\n",
    "# LOCAL_DRIVER = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "# local_conn_str = f\"DRIVER={LOCAL_DRIVER};SERVER={LOCAL_SERVER};DATABASE={LOCAL_DATABASE};Trusted_Connection=yes;TrustServerCertificate=yes\"\n",
    "\n",
    "# # Ruta a la carpeta con los archivos SQL\n",
    "# SQL_FOLDER_PATH = 'src/sql/'\n",
    " \n",
    "# #  Consulta SQL en Azure SQL\n",
    "# SQL_QUERY = \"\"\"\n",
    "#   SELECT\n",
    "#     Customer_ID,\n",
    "#     Edad,\n",
    "#     Fecha_nacimiento,\n",
    "#     GENERO,\n",
    "#     CAST(codigopostalid AS INT) AS CP,\n",
    "#     poblacion,\n",
    "#     provincia,\n",
    "#     STATUS_SOCIAL,\n",
    "#     [RENTA_MEDIA_ESTIMADA],\n",
    "#     [ENCUESTA_ZONA_CLIENTE_VENTA],\n",
    "#     [ENCUESTA_CLIENTE_ZONA_TALLER],\n",
    "#     [A], [B], [C], [D], [E], [F], [G], [H], [I], [J], [K], [U2],\n",
    "#     [Max_Mosaic_G], [Max_Mosaic2], [Renta_Media], [F2], [Mosaic_number]\n",
    "#   FROM\n",
    "#     [DATAEX].[003_clientes] cliente\n",
    "#   LEFT JOIN  \n",
    "#     [DATAEX].[005_cp] cp ON cliente.CODIGO_POSTAL = cp.CP\n",
    "#   LEFT JOIN\n",
    "#     [DATAEX].[019_mosaic] mosaic ON try_cast(cp.codigopostalid AS INT) = try_cast(mosaic.CP AS INT)\n",
    "# \"\"\"\n",
    " \n",
    "# # üîπ Nombre de la tabla en SQL Server Local\n",
    "# NEW_TABLE_NAME = \"Dim_customer\"\n",
    " \n",
    "# try:\n",
    "#     #  Conectar a Azure SQL\n",
    "#     print(f\"Conectando a Azure SQL...\")\n",
    "#     conn_azure = pyodbc.connect(azure_conn_str)\n",
    "   \n",
    "#     # üîπ Ejecutar la consulta en Azure SQL\n",
    "#     print(f\"Ejecutando consulta en Azure SQL...\")\n",
    "#     df = pd.read_sql(SQL_QUERY, conn_azure)\n",
    " \n",
    "#     if df.empty:\n",
    "#         print(f\" La consulta no devolvi√≥ resultados. No se crear√° la tabla en SQL Server Local.\")\n",
    "#     else:\n",
    "#         print(f\"   - Datos extra√≠dos: {df.shape[0]} filas\")\n",
    " \n",
    "#         #  Convertir NaN en columnas num√©ricas a 0\n",
    "#         df = df.fillna(0)\n",
    " \n",
    "#         #  Convertir valores num√©ricos problem√°ticos\n",
    "#         for col in df.select_dtypes(include=['float64']).columns:\n",
    "#             df[col] = df[col].astype(np.float32)  # Reducir precisi√≥n\n",
    "       \n",
    "#         for col in df.select_dtypes(include=['int64']).columns:\n",
    "#             df[col] = df[col].astype(np.int32)  # Evitar valores fuera de rango\n",
    "       \n",
    "#         #  Conectar a SQL Server Local\n",
    "#         print(f\"Conectando a SQL Server Local...\")\n",
    "#         conn_local = pyodbc.connect(local_conn_str)\n",
    "       \n",
    "#         with conn_local.cursor() as cursor:\n",
    "#             # üîπ Eliminar la tabla si ya existe\n",
    "#             drop_table_sql = f\"DROP TABLE IF EXISTS {NEW_TABLE_NAME}\"\n",
    "#             cursor.execute(drop_table_sql)\n",
    "#             conn_local.commit()\n",
    "#             print(f\"   - Tabla eliminada si exist√≠a.\")\n",
    " \n",
    "#             # üîπ Crear la tabla en SQL Server Local con tipos de datos ajustados\n",
    "#             columns_sql = []\n",
    "#             for col in df.columns:\n",
    "#                 col_type = df[col].dtype\n",
    "#                 if np.issubdtype(col_type, np.float32) or np.issubdtype(col_type, np.float64):\n",
    "#                     columns_sql.append(f'[{col}] FLOAT')\n",
    "#                 elif np.issubdtype(col_type, np.int32) or np.issubdtype(col_type, np.int64):\n",
    "#                     columns_sql.append(f'[{col}] INT')\n",
    "#                 else:\n",
    "#                     columns_sql.append(f'[{col}] NVARCHAR(255)')\n",
    " \n",
    "#             create_table_sql = f\"CREATE TABLE {NEW_TABLE_NAME} ({', '.join(columns_sql)});\"\n",
    "#             cursor.execute(create_table_sql)\n",
    "#             conn_local.commit()\n",
    "#             print(f\"   - Tabla {NEW_TABLE_NAME} creada correctamente en SQL Server Local.\")\n",
    " \n",
    "#             # Insertar los datos en SQL Server Local\n",
    "#             placeholders = ', '.join(['?' for _ in df.columns])\n",
    "#             insert_sql = f\"INSERT INTO {NEW_TABLE_NAME} VALUES ({placeholders})\"\n",
    " \n",
    "#             cursor.fast_executemany = True\n",
    "#             cursor.executemany(insert_sql, df.values.tolist())\n",
    "#             conn_local.commit()\n",
    " \n",
    "#             print(f\"   - {df.shape[0]} filas insertadas en {NEW_TABLE_NAME}.\")\n",
    " \n",
    "# except Exception as e:\n",
    "#     print(f\" Error: {e}\")\n",
    " \n",
    "# finally:\n",
    "#     if 'conn_azure' in locals():\n",
    "#         conn_azure.close()\n",
    "#     if 'conn_local' in locals():\n",
    "#         conn_local.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consulta SQL desde sql_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 16:24:15,738 - INFO - Conectando a Azure SQL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 16:24:16,084 - INFO - Conectando a SQL Server Local...\n",
      "2025-03-20 16:24:16,090 - INFO - Ejecutando Dim_customer.sql en Azure SQL...\n",
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_18352\\2288398914.py:41: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql_query, conn)\n",
      "2025-03-20 16:24:18,224 - INFO - Datos extra√≠dos para Dim_customer.sql: 44053 filas\n",
      "2025-03-20 16:24:18,297 - INFO - Tabla Dim_customer eliminada si exist√≠a.\n",
      "2025-03-20 16:24:18,300 - INFO - Tabla Dim_customer creada correctamente en SQL Server Local.\n",
      "2025-03-20 16:24:19,371 - INFO - 44053 filas insertadas en Dim_customer.\n",
      "2025-03-20 16:24:19,371 - INFO - Ejecutando Dim_geo.sql en Azure SQL...\n",
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_18352\\2288398914.py:41: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql_query, conn)\n",
      "2025-03-20 16:24:19,417 - INFO - Datos extra√≠dos para Dim_geo.sql: 12 filas\n",
      "2025-03-20 16:24:19,422 - INFO - Tabla Dim_geo eliminada si exist√≠a.\n",
      "2025-03-20 16:24:19,427 - INFO - Tabla Dim_geo creada correctamente en SQL Server Local.\n",
      "2025-03-20 16:24:19,429 - INFO - 12 filas insertadas en Dim_geo.\n",
      "2025-03-20 16:24:19,429 - INFO - Ejecutando Dim_product.sql en Azure SQL...\n",
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_18352\\2288398914.py:41: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql_query, conn)\n",
      "2025-03-20 16:24:19,473 - INFO - Datos extra√≠dos para Dim_product.sql: 404 filas\n",
      "2025-03-20 16:24:19,473 - INFO - Tabla Dim_product eliminada si exist√≠a.\n",
      "2025-03-20 16:24:19,473 - INFO - Tabla Dim_product creada correctamente en SQL Server Local.\n",
      "2025-03-20 16:24:19,491 - INFO - 404 filas insertadas en Dim_product.\n",
      "2025-03-20 16:24:19,492 - INFO - Ejecutando Dim_t.sql en Azure SQL...\n",
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_18352\\2288398914.py:41: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql_query, conn)\n",
      "2025-03-20 16:24:19,583 - INFO - Datos extra√≠dos para Dim_t.sql: 3652 filas\n",
      "2025-03-20 16:24:19,589 - INFO - Tabla Dim_t eliminada si exist√≠a.\n",
      "2025-03-20 16:24:19,593 - INFO - Tabla Dim_t creada correctamente en SQL Server Local.\n",
      "2025-03-20 16:24:19,653 - INFO - 3652 filas insertadas en Dim_t.\n",
      "2025-03-20 16:24:19,653 - INFO - Ejecutando Fact.sql en Azure SQL...\n",
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_18352\\2288398914.py:41: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql_query, conn)\n",
      "2025-03-20 16:24:23,201 - INFO - Datos extra√≠dos para Fact.sql: 58049 filas\n",
      "2025-03-20 16:24:23,382 - INFO - Tabla Fact eliminada si exist√≠a.\n",
      "2025-03-20 16:24:23,382 - INFO - Tabla Fact creada correctamente en SQL Server Local.\n",
      "2025-03-20 16:24:30,180 - INFO - 58049 filas insertadas en Fact.\n",
      "2025-03-20 16:24:30,243 - INFO - \n",
      "¬°Proceso completado!\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Configuraci√≥n de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Conexi√≥n a **Azure SQL**\n",
    "AZURE_SERVER = 'uaxmathfis.database.windows.net'\n",
    "AZURE_DATABASE = 'usecases'\n",
    "AZURE_DRIVER = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "azure_conn_str = f\"DRIVER={AZURE_DRIVER};SERVER={AZURE_SERVER};DATABASE={AZURE_DATABASE};Authentication=ActiveDirectoryInteractive\"\n",
    "\n",
    "# Conexi√≥n a **SQL Server LOCAL**\n",
    "LOCAL_SERVER = 'localhost'\n",
    "LOCAL_DATABASE = 'master'\n",
    "LOCAL_DRIVER = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "local_conn_str = f\"DRIVER={LOCAL_DRIVER};SERVER={LOCAL_SERVER};DATABASE={LOCAL_DATABASE};Trusted_Connection=yes;TrustServerCertificate=yes\"\n",
    "\n",
    "# Ruta a la carpeta con los archivos SQL\n",
    "SQL_FOLDER_PATH = 'src/sql/'\n",
    "\n",
    "# Nombres de los archivos SQL\n",
    "sql_files = [\n",
    "    'Dim_customer.sql',\n",
    "    'Dim_geo.sql',\n",
    "    'Dim_product.sql',\n",
    "    'Dim_t.sql',\n",
    "    'Fact.sql'\n",
    "]\n",
    "\n",
    "def execute_sql_file(conn, sql_file_path):\n",
    "    \"\"\"Ejecuta un archivo SQL y devuelve un DataFrame con los resultados.\"\"\"\n",
    "    try:\n",
    "        with open(sql_file_path, 'r', encoding='utf-8') as file:\n",
    "            sql_query = file.read()\n",
    "        df = pd.read_sql(sql_query, conn)\n",
    "        return df if df is not None else pd.DataFrame()  # Devuelve un DataFrame vac√≠o si no hay resultados\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error ejecutando {sql_file_path}: {e}\")\n",
    "        return pd.DataFrame()  # Devuelve un DataFrame vac√≠o en caso de error\n",
    "\n",
    "def create_table(conn, table_name, df):\n",
    "    \"\"\"Crea una tabla en la base de datos local basada en el DataFrame.\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        logging.warning(f\"El DataFrame para {table_name} est√° vac√≠o o no es v√°lido.\")\n",
    "        return\n",
    "\n",
    "    with conn.cursor() as cursor:\n",
    "        # Eliminar la tabla si ya existe\n",
    "        drop_table_sql = f\"DROP TABLE IF EXISTS {table_name}\"\n",
    "        cursor.execute(drop_table_sql)\n",
    "        conn.commit()\n",
    "        logging.info(f\"Tabla {table_name} eliminada si exist√≠a.\")\n",
    "\n",
    "        # Crear la tabla en SQL Server Local con tipos de datos ajustados\n",
    "        columns_sql = []\n",
    "        for col in df.columns:\n",
    "            col_type = df[col].dtype  # Acceder al dtype de la columna\n",
    "            if np.issubdtype(col_type, np.float32) or np.issubdtype(col_type, np.float64):\n",
    "                columns_sql.append(f'[{col}] FLOAT')\n",
    "            elif np.issubdtype(col_type, np.int32) or np.issubdtype(col_type, np.int64):\n",
    "                columns_sql.append(f'[{col}] INT')\n",
    "            else:\n",
    "                columns_sql.append(f'[{col}] NVARCHAR(255)')\n",
    "                \n",
    "        create_table_sql = f\"\"\"\n",
    "        CREATE TABLE {table_name} (\n",
    "            {', '.join(columns_sql)}\n",
    "        );\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table_sql)\n",
    "        conn.commit()\n",
    "        logging.info(f\"Tabla {table_name} creada correctamente en SQL Server Local.\")\n",
    "\n",
    "def insert_data(conn, table_name, df):\n",
    "    \"\"\"Inserta los datos del DataFrame en la tabla de la base de datos local.\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        logging.warning(f\"No hay datos para insertar en {table_name}.\")\n",
    "        return\n",
    "\n",
    "    with conn.cursor() as cursor:\n",
    "        placeholders = ', '.join(['?' for _ in df.columns])\n",
    "        insert_sql = f\"INSERT INTO {table_name} VALUES ({placeholders})\"\n",
    "        cursor.fast_executemany = True\n",
    "        cursor.executemany(insert_sql, df.values.tolist())\n",
    "        conn.commit()\n",
    "        logging.info(f\"{df.shape[0]} filas insertadas en {table_name}.\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Conectar a Azure SQL\n",
    "        logging.info(\"Conectando a Azure SQL...\")\n",
    "        conn_azure = pyodbc.connect(azure_conn_str)\n",
    "\n",
    "        # Conectar a SQL Server Local\n",
    "        logging.info(\"Conectando a SQL Server Local...\")\n",
    "        conn_local = pyodbc.connect(local_conn_str)\n",
    "\n",
    "        for sql_file in sql_files:\n",
    "            try:\n",
    "                sql_file_path = os.path.join(SQL_FOLDER_PATH, sql_file)\n",
    "                logging.info(f\"Ejecutando {sql_file} en Azure SQL...\")\n",
    "\n",
    "                # Ejecutar la consulta y obtener los datos\n",
    "                df = execute_sql_file(conn_azure, sql_file_path)\n",
    "\n",
    "                if df.empty:\n",
    "                    logging.warning(f\"La consulta no devolvi√≥ resultados para {sql_file}. No se crear√° la tabla en SQL Server Local.\")\n",
    "                    continue\n",
    "\n",
    "                logging.info(f\"Datos extra√≠dos para {sql_file}: {df.shape[0]} filas\")\n",
    "\n",
    "                # Convertir NaN en columnas num√©ricas a 0\n",
    "                df = df.fillna(0)\n",
    "\n",
    "                # Convertir valores num√©ricos problem√°ticos\n",
    "                for col in df.select_dtypes(include=['float64']).columns:\n",
    "                    df[col] = df[col].astype(np.float32)  # Reducir precisi√≥n\n",
    "\n",
    "                for col in df.select_dtypes(include=['int64']).columns:\n",
    "                    df[col] = df[col].astype(np.int32)  # Evitar valores fuera de rango\n",
    "\n",
    "                # Crear la tabla e insertar los datos\n",
    "                table_name = sql_file.split('.')[0]\n",
    "                create_table(conn_local, table_name, df)\n",
    "                insert_data(conn_local, table_name, df)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error procesando {sql_file}: {e}\")\n",
    "                continue  # Continuar con el siguiente archivo\n",
    "\n",
    "    except pyodbc.Error as e:\n",
    "        logging.error(f\"Error de conexi√≥n a la base de datos: {e}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error inesperado: {e}\")\n",
    "    finally:\n",
    "        if 'conn_azure' in locals():\n",
    "            conn_azure.close()\n",
    "        if 'conn_local' in locals():\n",
    "            conn_local.close()\n",
    "\n",
    "    logging.info(\"\\n¬°Proceso completado!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
